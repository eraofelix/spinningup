#!/usr/bin/env python3
"""
æµ‹è¯•è®­ç»ƒå¥½çš„ PPO æ¨¡å‹
"""
import torch
import gymnasium as gym
import gymnasium_robotics
import numpy as np
import os
import argparse
import sys
sys.path.append('spinup')
from spinup.algos.pytorch.ppo.ppo import MLPActorCritic
from spinup.algos.pytorch.ppo.cnn_attention import CNNActorCritic

def detect_model_architecture(model_path):
    """è‡ªåŠ¨æ£€æµ‹æ¨¡å‹æ¶æ„ï¼ˆæ”¯æŒMLPå’ŒCNNï¼‰"""
    checkpoint = torch.load(model_path, map_location='cpu')
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯CNNæ¨¡å‹
    has_cnn_layers = any('cnn_extractor' in key for key in checkpoint.keys())
    
    if has_cnn_layers:
        print("ğŸ–¼ï¸  æ£€æµ‹åˆ°CNNæ¨¡å‹")
        return detect_cnn_architecture(checkpoint)
    else:
        print("ğŸ“Š æ£€æµ‹åˆ°MLPæ¨¡å‹")
        return detect_mlp_architecture(checkpoint)

def detect_cnn_architecture(checkpoint):
    """æ£€æµ‹CNNæ¨¡å‹æ¶æ„"""
    # åˆ†æCNNç‰¹å¾æå–å™¨
    cnn_weights = {k: v for k, v in checkpoint.items() if 'cnn_extractor' in k}
    
    # æ£€æµ‹å·ç§¯å±‚é€šé“æ•°
    conv_channels = []
    for key in sorted(cnn_weights.keys()):
        if 'conv_layers' in key and 'weight' in key:
            # æå–å±‚å·
            parts = key.split('.')
            for i, part in enumerate(parts):
                if part == 'conv_layers' and i + 1 < len(parts):
                    layer_idx = int(parts[i + 1])
                    if layer_idx % 3 == 0:  # æ¯3å±‚æ˜¯ä¸€ä¸ªå·ç§¯å±‚ï¼ˆConv2d, BatchNorm, ReLUï¼‰
                        conv_idx = layer_idx // 3
                        if conv_idx < 4:  # åªå–å‰4ä¸ªå·ç§¯å±‚
                            weight_shape = cnn_weights[key].shape
                            if len(weight_shape) == 4:  # Conv2dæƒé‡
                                out_channels = weight_shape[0]
                                conv_channels.append(out_channels)
    
    # æ£€æµ‹å…¨è¿æ¥å±‚
    fc_weights = {k: v for k, v in checkpoint.items() if 'policy_net' in k and 'weight' in key}
    hidden_sizes = []
    for key in sorted(fc_weights.keys()):
        weight_shape = fc_weights[key].shape
        if len(weight_shape) == 2:  # çº¿æ€§å±‚æƒé‡
            hidden_sizes.append(weight_shape[0])
    
    # ç§»é™¤æœ€åä¸€å±‚ï¼ˆè¾“å‡ºå±‚ï¼‰
    if len(hidden_sizes) > 1:
        hidden_sizes = hidden_sizes[:-1]
    
    print(f"CNNå·ç§¯å±‚é€šé“æ•°: {conv_channels[:4]}")
    print(f"CNNå…¨è¿æ¥å±‚å¤§å°: {hidden_sizes}")
    
    return {
        'type': 'cnn',
        'cnn_channels': conv_channels[:4] if len(conv_channels) >= 4 else [16, 32, 64, 128],
        'hidden_sizes': hidden_sizes if hidden_sizes else [128, 64],
        'feature_dim': hidden_sizes[0] if hidden_sizes else 256
    }

def detect_mlp_architecture(checkpoint):
    """æ£€æµ‹MLPæ¨¡å‹æ¶æ„"""
    # åˆ†æç­–ç•¥ç½‘ç»œçš„æƒé‡
    pi_weights = {k: v for k, v in checkpoint.items() if k.startswith('pi.')}
    
    # æ‰¾åˆ°æ‰€æœ‰çº¿æ€§å±‚çš„æƒé‡
    linear_layers = []
    for key in pi_weights.keys():
        if 'weight' in key and 'mu_net' in key:
            layer_num = int(key.split('.')[2])  # è·å–å±‚å·
            weight_shape = pi_weights[key].shape
            linear_layers.append((layer_num, weight_shape))
    
    # æŒ‰å±‚å·æ’åº
    linear_layers.sort(key=lambda x: x[0])
    
    # æ ¹æ®æƒé‡å½¢çŠ¶æ¨æ–­éšè—å±‚å¤§å°
    hidden_sizes = []
    for i, (layer_num, shape) in enumerate(linear_layers):
        if i == 0:  # ç¬¬ä¸€å±‚ï¼šè¾“å…¥å±‚ -> éšè—å±‚
            hidden_sizes.append(shape[0])
        elif i == len(linear_layers) - 1:  # æœ€åä¸€å±‚ï¼šè¾“å‡ºå±‚
            continue
        else:  # ä¸­é—´å±‚ï¼šéšè—å±‚
            hidden_sizes.append(shape[0])
    
    print(f"MLPéšè—å±‚å¤§å°: {hidden_sizes}")
    
    return {
        'type': 'mlp',
        'hidden_sizes': hidden_sizes
    }

def load_model(model_path, env, architecture_info=None):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆæ”¯æŒMLPå’ŒCNNï¼‰"""
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¶æ„ï¼Œè‡ªåŠ¨æ£€æµ‹
    if architecture_info is None:
        architecture_info = detect_model_architecture(model_path)
    
    # æ ¹æ®æ¨¡å‹ç±»å‹åˆ›å»ºç½‘ç»œç»“æ„
    if architecture_info['type'] == 'cnn':
        print("ğŸ–¼ï¸  åˆ›å»ºCNNç½‘ç»œ...")
        ac = CNNActorCritic(
            env.observation_space, 
            env.action_space,
            feature_dim=architecture_info.get('feature_dim', 256),
            hidden_sizes=architecture_info.get('hidden_sizes', [128, 64]),
            cnn_channels=architecture_info.get('cnn_channels', [16, 32, 64, 128]),
            attention_reduction=8,
            dropout_rate=0.1
        )
    else:
        print("ğŸ“Š åˆ›å»ºMLPç½‘ç»œ...")
        ac = MLPActorCritic(
            env.observation_space, 
            env.action_space, 
            hidden_sizes=architecture_info.get('hidden_sizes', [64, 64])
        )
    
    # åŠ è½½æ¨¡å‹æƒé‡
    checkpoint = torch.load(model_path, map_location='cpu')
    ac.load_state_dict(checkpoint)
    
    return ac

def test_model(env_name, model_path, num_episodes=5, render=True, architecture_info=None):
    """æµ‹è¯•æ¨¡å‹æ€§èƒ½ï¼ˆæ”¯æŒMLPå’ŒCNNï¼‰"""
    # åˆ›å»ºç¯å¢ƒ
    env = gym.make(env_name, render_mode='human' if render else None)
    
    # åŠ è½½æ¨¡å‹ï¼ˆè‡ªåŠ¨æ£€æµ‹æ¶æ„ï¼‰
    ac = load_model(model_path, env, architecture_info=architecture_info)
    ac.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    
    print(f"å¼€å§‹æµ‹è¯•æ¨¡å‹: {model_path}")
    print(f"ç¯å¢ƒ: {env_name}")
    print(f"æµ‹è¯•å›åˆæ•°: {num_episodes}")
    print("=" * 50)
    
    episode_returns = []
    
    for episode in range(num_episodes):
        obs, _ = env.reset()
        episode_return = 0
        episode_length = 0
        done = False
        
        while not done:
            # è·å–åŠ¨ä½œï¼ˆç¡®å®šæ€§ç­–ç•¥ï¼Œä¸æ·»åŠ å™ªå£°ï¼‰
            with torch.no_grad():
                # å¤„ç†å›¾åƒè§‚æµ‹
                if len(obs.shape) == 3:  # å›¾åƒè§‚æµ‹ (H, W, C)
                    obs_tensor = torch.as_tensor(obs, dtype=torch.float32).unsqueeze(0)
                    action = ac.act(obs_tensor)
                    # ç¡®ä¿åŠ¨ä½œæ˜¯æ­£ç¡®çš„å½¢çŠ¶ï¼šä» (1, 3) è½¬æ¢ä¸º (3,)
                    if len(action.shape) > 1 and action.shape[0] == 1:
                        action = action[0]  # å–ç¬¬ä¸€ä¸ªï¼ˆä¹Ÿæ˜¯å”¯ä¸€çš„ï¼‰åŠ¨ä½œ
                else:  # å‘é‡è§‚æµ‹
                    action = ac.act(torch.as_tensor(obs, dtype=torch.float32))
            
            # æ‰§è¡ŒåŠ¨ä½œ
            obs, reward, terminated, truncated, _ = env.step(action)
            done = terminated or truncated
            
            episode_return += reward
            episode_length += 1
            
            if render:
                env.render()
        
        episode_returns.append(episode_return)
        print(f"Episode {episode + 1}: Return = {episode_return:.2f}, Length = {episode_length}")
    
    env.close()
    
    # ç»Ÿè®¡ç»“æœ
    mean_return = np.mean(episode_returns)
    std_return = np.std(episode_returns)
    max_return = np.max(episode_returns)
    min_return = np.min(episode_returns)
    
    print("=" * 50)
    print("æµ‹è¯•ç»“æœç»Ÿè®¡:")
    print(f"å¹³å‡å¥–åŠ±: {mean_return:.2f} Â± {std_return:.2f}")
    print(f"æœ€é«˜å¥–åŠ±: {max_return:.2f}")
    print(f"æœ€ä½å¥–åŠ±: {min_return:.2f}")
    print(f"æµ‹è¯•å›åˆæ•°: {num_episodes}")

def find_latest_model(experiment_dir):
    """æ‰¾åˆ°æœ€æ–°çš„æ¨¡å‹æ–‡ä»¶"""
    model_files = []
    for file in os.listdir(experiment_dir):
        if file.startswith('model_epoch_') and file.endswith('.pth'):
            model_files.append(file)
    
    if not model_files:
        raise FileNotFoundError(f"åœ¨ {experiment_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
    
    # æŒ‰epochç¼–å·æ’åºï¼Œè¿”å›æœ€æ–°çš„
    model_files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))
    return os.path.join(experiment_dir, model_files[-1])

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="æµ‹è¯• PPO æ¨¡å‹")
    parser.add_argument('--env', type=str, default='HalfCheetah-v5', help='ç¯å¢ƒåç§°')
    parser.add_argument('--model_path', type=str, help='æ¨¡å‹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--experiment_dir', type=str, help='å®éªŒç›®å½•ï¼ˆè‡ªåŠ¨æ‰¾æœ€æ–°æ¨¡å‹ï¼‰')
    parser.add_argument('--episodes', type=int, default=5, help='æµ‹è¯•å›åˆæ•°')
    parser.add_argument('--no_render', action='store_true', help='ä¸æ˜¾ç¤ºæ¸²æŸ“')
    # CNNç½‘ç»œå‚æ•°ï¼ˆå¯é€‰ï¼Œè‡ªåŠ¨æ£€æµ‹ï¼‰
    parser.add_argument('--feature_dim', type=int, help='CNNç‰¹å¾ç»´åº¦ï¼ˆå¯é€‰ï¼Œè‡ªåŠ¨æ£€æµ‹ï¼‰')
    parser.add_argument('--cnn_channels', type=int, nargs=4, help='CNNå„å±‚é€šé“æ•°ï¼ˆå¯é€‰ï¼Œè‡ªåŠ¨æ£€æµ‹ï¼‰')
    parser.add_argument('--hidden_sizes', type=int, nargs='+', help='å…¨è¿æ¥å±‚éšè—å±‚å¤§å°ï¼ˆå¯é€‰ï¼Œè‡ªåŠ¨æ£€æµ‹ï¼‰')
    
    # MLPç½‘ç»œå‚æ•°ï¼ˆå‘åå…¼å®¹ï¼‰
    parser.add_argument('--hid', type=int, help='éšè—å±‚ç¥ç»å…ƒæ•°é‡ï¼ˆå¯é€‰ï¼Œè‡ªåŠ¨æ£€æµ‹ï¼‰')
    parser.add_argument('--l', type=int, help='éšè—å±‚æ•°é‡ï¼ˆå¯é€‰ï¼Œè‡ªåŠ¨æ£€æµ‹ï¼‰')
    
    args = parser.parse_args()
    
    # ç¡®å®šæ¨¡å‹è·¯å¾„
    if args.model_path:
        model_path = args.model_path
    elif args.experiment_dir:
        model_path = find_latest_model(args.experiment_dir)
        print(f"æ‰¾åˆ°æœ€æ–°æ¨¡å‹: {model_path}")
    else:
        # é»˜è®¤ä½¿ç”¨æœ€æ–°çš„å®éªŒç›®å½•
        import glob
        experiment_dirs = glob.glob('data/ppo_*')
        if not experiment_dirs:
            print("é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°å®éªŒç›®å½•")
            exit(1)
        
        latest_dir = max(experiment_dirs, key=os.path.getctime)
        model_path = find_latest_model(latest_dir)
        print(f"ä½¿ç”¨æœ€æ–°å®éªŒç›®å½•: {latest_dir}")
        print(f"æ‰¾åˆ°æœ€æ–°æ¨¡å‹: {model_path}")
    
    # åˆ›å»ºæ¶æ„ä¿¡æ¯ï¼ˆå¦‚æœæŒ‡å®šäº†å‚æ•°ï¼‰
    architecture_info = None
    if any([args.feature_dim, args.cnn_channels, args.hidden_sizes, args.hid, args.l]):
        print("ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹æ¶æ„å‚æ•°...")
        architecture_info = {}
        
        # åˆ¤æ–­æ˜¯CNNè¿˜æ˜¯MLPå‚æ•°
        if any([args.feature_dim, args.cnn_channels]):
            # CNNå‚æ•°
            architecture_info['type'] = 'cnn'
            if args.feature_dim:
                architecture_info['feature_dim'] = args.feature_dim
            if args.cnn_channels:
                architecture_info['cnn_channels'] = args.cnn_channels
            if args.hidden_sizes:
                architecture_info['hidden_sizes'] = args.hidden_sizes
        elif args.hid and args.l:
            # MLPå‚æ•°ï¼ˆå‘åå…¼å®¹ï¼‰
            architecture_info['type'] = 'mlp'
            architecture_info['hidden_sizes'] = [args.hid] * args.l
        elif args.hidden_sizes:
            # åªæœ‰hidden_sizesï¼Œéœ€è¦åˆ¤æ–­ç¯å¢ƒç±»å‹
            if args.env == 'CarRacing-v3':
                architecture_info['type'] = 'cnn'
                architecture_info['hidden_sizes'] = args.hidden_sizes
            else:
                architecture_info['type'] = 'mlp'
                architecture_info['hidden_sizes'] = args.hidden_sizes
        
        print(f"æŒ‡å®šæ¶æ„: {architecture_info}")
    else:
        print("è‡ªåŠ¨æ£€æµ‹æ¨¡å‹æ¶æ„...")
    
    # æµ‹è¯•æ¨¡å‹
    test_model(
        env_name=args.env,
        model_path=model_path,
        num_episodes=args.episodes,
        render=not args.no_render,
        architecture_info=architecture_info
    )

